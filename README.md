**Alumno**: Pablo Brahim  
**Materia**: Procesamiento de Lenguaje Natural  
**Carrera**: Especializaci칩n en Inteligencia Artificial - FIUBA  

## Contenido
- [Introducci칩n](#introduccion)
- [Desaf칤o 1 - Consigna](#desafio-1---consigna)
- [Desaf칤o 2 - Consigna](#desafio-2---consigna)
- [Desaf칤o 3 - Consigna](#desafio-3---consigna)
- [Desaf칤o 4 - Consigna](#desafio-4---consigna)

---

## Introduccion

Desaf칤os de la materia Procesamiento de Lenguaje Natural en el cuarto bimestre del a침o 2025.

---

## Desaf칤o 1 - Consigna

1. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos. Estudiar los 5 documentos m치s similares de cada uno analizar si tiene sentido la similaridad seg칰n el contenido del texto y la etiqueta de clasificaci칩n.  
2. Construir un modelo de clasificaci칩n por prototipos (tipo zero-shot). Clasificar los documentos de un conjunto de test comparando cada uno con todos los de entrenamiento y asignar la clase al label del documento del conjunto de entrenamiento con mayor similaridad.  
3. Entrenar modelos de clasificaci칩n Na칦ve Bayes para maximizar el desempe침o de clasificaci칩n (f1-score macro) en el conjunto de datos de test. Considerar cambiar par치metros de instanciaci칩n del vectorizador y los modelos y probar modelos de Na칦ve Bayes Multinomial y ComplementNB.  
4. Transponer la matriz documento-t칠rmino. De esa manera se obtiene una matriz t칠rmino-documento que puede ser interpretada como una colecci칩n de vectorizaci칩n de palabras. Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 m치s similares. La elecci칩n de palabras no debe ser al azar para evitar la aparici칩n de t칠rminos poco interpretables, elegirlas "manualmente".

游늽 [Notebook Desaf칤o 1](Desafio_1/Desafio_1.ipynb)

---

## Desaf칤o 2 - Consigna

1. Crear sus propios vectores con Gensim basado en lo visto en clase con otro dataset.  
2. Probar t칠rminos de inter칠s y explicar similitudes en el espacio de embeddings (sacar conclusiones entre palabras similitudes y diferencias).  
3. Graficarlos.  
4. Obtener conclusiones.  

游늽 [Notebook Desaf칤o 2](Desafio_2/Desafio_2.ipynb)

---

## Desaf칤o 3 - Consigna

1. Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.  
2. Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validaci칩n.  
3. Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.  
4. Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determin칤stico y estoc치stico. En este 칰ltimo caso observar el efecto de la temperatura en la generaci칩n de secuencias.  

游닂 [Colab Desaf칤o 3](https://colab.research.google.com/drive/1Rw_dGf4CJLj7RVcHxTKO7dzv_NaaGr9p#scrollTo=Iv5PEwGzZA9-)

---

## Desaf칤o 4 - Consigna

Replicar el modelo en PyTorch.  
- Extender el entrenamiento a m치s datos y tama침os de secuencias mayores.  
- Explorar el impacto de la cantidad de neuronas en las capas recurrentes.  
- Mostrar 5 ejemplos de traducciones generadas.  
Replicar y extender el traductor:  

游닂 [Colab Desaf칤o 4](Desafio_4/Desafio_4.ipynb)
