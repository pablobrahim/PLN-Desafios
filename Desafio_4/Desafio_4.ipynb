{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfa39F4lsLf3"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## LSTM Traductor\n",
    "Ejemplo basado en [LINK](https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FGmtK8J19PNk"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --no-cache-dir gdown --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cq3YXak9sGHd"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vgYatMIdk_eT",
    "outputId": "9a2a7c2b-bf07-4763-b7d1-081906404c35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OYpIWGaXxfKe",
    "outputId": "aa70d148-97bf-43fe-c352-916e69ff021d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in c:\\users\\pbrahim\\appdata\\local\\anaconda3\\lib\\site-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torchinfo\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GHFPS5KNxgR9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "if os.access('torch_helpers.py', os.F_OK) is False:\n",
    "    if platform.system() == 'Windows':\n",
    "        !curl !wget https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py > torch_helpers.py\n",
    "    else:\n",
    "        !wget torch_helpers.py https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFLCmUlNhGU3"
   },
   "source": [
    "Esta celda entrena el modelo de traducción automática mediante un ciclo que procesa los datos por épocas. En cada iteración, el modelo aprende de los datos de entrenamiento y se valida con ejemplos no vistos.\n",
    "\n",
    "El proceso calcula dos métricas principales: la pérdida (loss) que indica el error del modelo, y la precisión (accuracy) que mide el porcentaje de palabras traducidas correctamente.\n",
    "\n",
    "Los resultados se almacenan para analizar la evolución del aprendizaje y el rendimiento final del modelo traductor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tP-fbmHUgbtp"
   },
   "outputs": [],
   "source": [
    "def sequence_acc(output, target):\n",
    "    predictions = output.argmax(dim=-1)\n",
    "\n",
    "    correct = (predictions == target).float()\n",
    "\n",
    "\n",
    "    accuracy = correct.mean()\n",
    "    return accuracy\n",
    "\n",
    "def train(model, train_loader, valid_loader, optimizer, criterion, epochs=100):\n",
    "    # Defino listas para realizar graficas de los resultados\n",
    "    train_loss = []\n",
    "    train_accuracy = []\n",
    "    valid_loss = []\n",
    "    valid_accuracy = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_train_accuracy = 0.0\n",
    "\n",
    "        for train_encoder_input, train_decoder_input, train_target in train_loader:\n",
    "\n",
    "            train_encoder_input = train_encoder_input.to(device)\n",
    "            train_decoder_input = train_decoder_input.to(device)\n",
    "            train_target = train_target.to(device)\n",
    "\n",
    "            # Seteo los gradientes en cero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(train_encoder_input, train_decoder_input)\n",
    "\n",
    "            loss = criterion(output.reshape(-1, output.shape[-1]),\n",
    "                           train_target.reshape(-1))\n",
    "\n",
    "            # Almaceno el error del batch\n",
    "            epoch_train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculo el accuracy del batch\n",
    "            accuracy = sequence_acc(output, train_target)\n",
    "            epoch_train_accuracy += accuracy.item()\n",
    "\n",
    "        epoch_train_loss = epoch_train_loss / len(train_loader)\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        epoch_train_accuracy = epoch_train_accuracy / len(train_loader)\n",
    "        train_accuracy.append(epoch_train_accuracy)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_encoder_input, valid_decoder_input, valid_target = next(iter(valid_loader))\n",
    "            valid_encoder_input = valid_encoder_input.to(device)\n",
    "            valid_decoder_input = valid_decoder_input.to(device)\n",
    "            valid_target = valid_target.to(device)\n",
    "\n",
    "            output = model(valid_encoder_input, valid_decoder_input)\n",
    "\n",
    "            epoch_valid_loss = criterion(output.reshape(-1, output.shape[-1]),\n",
    "                                       valid_target.reshape(-1))\n",
    "            epoch_valid_loss = epoch_valid_loss.item()\n",
    "            valid_loss.append(epoch_valid_loss)\n",
    "\n",
    "            epoch_valid_accuracy = sequence_acc(output, valid_target).item()\n",
    "            valid_accuracy.append(epoch_valid_accuracy)\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{epochs} - Train loss {epoch_train_loss:.3f} - Train accuracy {epoch_train_accuracy:.3f} - Valid Loss {epoch_valid_loss:.3f} - Valid accuracy {epoch_valid_accuracy:.3f}\")\n",
    "\n",
    "    history = {\n",
    "        \"loss\": train_loss,\n",
    "        \"accuracy\": train_accuracy,\n",
    "        \"val_loss\": valid_loss,\n",
    "        \"val_accuracy\": valid_accuracy,\n",
    "    }\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BFiCH8nxoIY"
   },
   "source": [
    "### 1 - Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHNkUaPp6aYq",
    "outputId": "edd3e76d-233a-4c71-d03a-0f78bbcbb31f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset ya se encuentra descargado\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "# Verificar si la carpeta ya existe\n",
    "if not os.path.exists('spa-eng'):\n",
    "    # Descargar zip si no existe\n",
    "    if not os.path.exists('spa-eng.zip'):\n",
    "        url = 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\n",
    "        output = 'spa-eng.zip'\n",
    "        gdown.download(url, output, quiet=False)\n",
    "    \n",
    "    # Descomprimir con Python\n",
    "    with zipfile.ZipFile('spa-eng.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "    print(\"Dataset descomprimido correctamente.\")\n",
    "else:\n",
    "    print(\"El dataset ya se encuentra descargado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-9aNLZBDtA5J",
    "outputId": "0d4edd00-3f3e-4ff2-c652-a7b3978d9a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows disponibles: 118964\n",
      "Cantidad de rows utilizadas: 29741\n"
     ]
    }
   ],
   "source": [
    "# dataset_file\n",
    "\n",
    "text_file = \"./spa-eng/spa.txt\"\n",
    "with open(text_file, encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "# Por limitaciones de RAM no se leen todas las filas\n",
    "MAX_NUM_SENTENCES = len(lines)/4\n",
    "#MAX_NUM_SENTENCES = 10000\n",
    "\n",
    "# Mezclar el dataset, forzar semilla siempre igual\n",
    "np.random.seed([40])\n",
    "np.random.shuffle(lines)\n",
    "\n",
    "input_sentences = []\n",
    "output_sentences = []\n",
    "output_sentences_inputs = []\n",
    "count = 0\n",
    "\n",
    "for line in lines:\n",
    "    count += 1\n",
    "    if count > MAX_NUM_SENTENCES:\n",
    "        break\n",
    "\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "\n",
    "    # Input sentence --> eng\n",
    "    # output --> spa\n",
    "    input_sentence, output = line.rstrip().split('\\t')\n",
    "\n",
    "    # output sentence (decoder_output) tiene <eos>\n",
    "    output_sentence = output + ' <eos>'\n",
    "    # output sentence input (decoder_input) tiene <sos>\n",
    "    output_sentence_input = '<sos> ' + output\n",
    "\n",
    "    input_sentences.append(input_sentence)\n",
    "    output_sentences.append(output_sentence)\n",
    "    output_sentences_inputs.append(output_sentence_input)\n",
    "\n",
    "print(\"Cantidad de rows disponibles:\", len(lines))\n",
    "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93IGMKFb73q7",
    "outputId": "25ba9259-5879-4131-ec9d-447b26e593e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A deal is a deal.',\n",
       " 'Un trato es un trato. <eos>',\n",
       " '<sos> Un trato es un trato.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentences[0], output_sentences[0], output_sentences_inputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P-ynUNP5xp6"
   },
   "source": [
    "### 2 - Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5WAZGOTfGyha"
   },
   "outputs": [],
   "source": [
    "# Definir el tamaño máximo del vocabulario\n",
    "MAX_VOCAB_SIZE = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eF1W6peoFGXA",
    "outputId": "80fc3828-e357-4e27-f4df-563eba10d423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario: 8085\n",
      "Sentencia de entrada más larga: 32\n"
     ]
    }
   ],
   "source": [
    "# Tokenizar las palabras con el Tokenizer de Keras\n",
    "# Definir una máxima cantidad de palabras a utilizar:\n",
    "# - num_words --> the maximum number of words to keep, based on word frequency.\n",
    "# - Only the most common num_words-1 words will be kept.\n",
    "from torch_helpers import Tokenizer\n",
    "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Sentencia de entrada más larga:\", max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zBzdKiTVIBYY",
    "outputId": "2a9bcd5e-a7b1-46f0-b758-d40dc43b7820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario: 13917\n",
      "Sentencia de salida más larga: 36\n"
     ]
    }
   ],
   "source": [
    "# tokenizador de español\n",
    "# A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n",
    "# sacamos los \"<>\" para que no afectar nuestros tokens\n",
    "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
    "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
    "\n",
    "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) # Se suma 1 por el primer <sos>\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Sentencia de salida más larga:\", max_out_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOpu9HKbr8Fb",
    "outputId": "383c2ef0-6575-444a-80ef-d902764c4eec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13918"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(word2idx_outputs))\n",
    "num_words_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pgLC706EQx3p"
   },
   "outputs": [],
   "source": [
    "max_input_len = 50\n",
    "max_out_len = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGOn9N57IuYz"
   },
   "source": [
    "A la hora de realiza padding es importante teneer en cuenta que en el encoder los ceros se agregan al comienoz y en el decoder al final. Esto es porque la salida del encoder está basado en las últimas palabras de la sentencia (son las más importantes), mientras que en el decoder está basado en el comienzo de la secuencia de salida ya que es la realimentación del sistema y termina con fin de sentencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q0Ob4hAWJkcv",
    "outputId": "44ae5f42-4e12-46f1-faff-4afa97085593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n",
      "Cantidad de rows del dataset: 29741\n",
      "encoder_input_sequences shape: (29741, 50)\n",
      "decoder_input_sequences shape: (29741, 50)\n"
     ]
    }
   ],
   "source": [
    "from torch_helpers import pad_sequences\n",
    "np.unicode_ = np.str_\n",
    "\n",
    "print(np.version.full_version)\n",
    "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
    "\n",
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
    "\n",
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VySR1pzx9UG",
    "outputId": "86d332af-ca3b-4299-f1c8-675a0c5eac58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output_sequences shape: (29741, 50)\n"
     ]
    }
   ],
   "source": [
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_output_sequences shape:\", decoder_output_sequences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQBVqaTyhqKX"
   },
   "source": [
    "Esta celda organiza los datos para el entrenamiento del modelo traductor. Convierte las secuencias de texto en tensores numéricos que PyTorch puede procesar eficientemente.\n",
    "\n",
    "La clase SequenceDataset estructura tres componentes esenciales: las secuencias de entrada para el codificador, las secuencias de entrada para el decodificador y las secuencias objetivo que el modelo debe aprender a predecir.\n",
    "\n",
    "Cada muestra del dataset contiene un trio de tensores listos para ser utilizados durante el entrenamiento del modelo de traducción automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "SD0bpM32yWfB"
   },
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, enc_input, dec_input, dec_output):\n",
    "        self.enc_tensors = torch.from_numpy(enc_input.astype(np.int32))\n",
    "        self.dec_in_tensors = torch.from_numpy(dec_input.astype(np.int32))\n",
    "        self.dec_out_tensors = torch.from_numpy(dec_output.astype(np.int64))\n",
    "        self.n_samples = self.dec_out_tensors.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.enc_tensors[idx], self.dec_in_tensors[idx], self.dec_out_tensors[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "data_set = SequenceDataset(encoder_input_sequences, decoder_input_sequences, decoder_output_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eH2dTBIhxnP"
   },
   "source": [
    " División de Datos para Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUDPZeuAU1RI",
    "outputId": "431fa2d5-c132-40bf-d2c1-3bc811f734de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestras de entrenamiento: 23793\n",
      "Muestras de validación: 5948\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "val_size = int(len(data_set) * 0.2)\n",
    "tr_size = len(data_set) - val_size\n",
    "\n",
    "training_data = torch.utils.data.Subset(data_set, range(tr_size))\n",
    "validation_data = torch.utils.data.Subset(data_set, range(tr_size, len(data_set)))\n",
    "\n",
    "print(\"Muestras de entrenamiento:\", len(training_data))\n",
    "print(\"Muestras de validación:\", len(validation_data))\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(training_data, batch_size=16, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(validation_data, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CJIsLBbj6rg"
   },
   "source": [
    "### 3 - Preparar los embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9OcT-DLzkHS8",
    "outputId": "632d9579-1378-43a4-fea8-8979621261bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los embeddings gloveembedding.pkl ya están descargados\n"
     ]
    }
   ],
   "source": [
    "# Descargar los embeddings desde un gogle drive (es la forma más rápida)\n",
    "# NOTA: No hay garantía de que estos links perduren, en caso de que no estén\n",
    "# disponibles descargar de la página oficial como se explica en el siguiente bloque\n",
    "import os\n",
    "import gdown\n",
    "if os.access('gloveembedding.pkl', os.F_OK) is False:\n",
    "    url = 'https://drive.google.com/uc?id=1wlDBOrxPq2-3htQ6ryVo7K1XnzLcfh4r&export=download'\n",
    "    output = 'gloveembedding.pkl'\n",
    "    gdown.download(url, output, quiet=False)\n",
    "else:\n",
    "    print(\"Los embeddings gloveembedding.pkl ya están descargados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxxMl5-2iO6Y"
   },
   "source": [
    "Esta celda define las clases para cargar y gestionar embeddings de palabras preentrenados (Glove y FastText). Permite convertir palabras a vectores numéricos y viceversa, manejar la serialización de los embeddings mediante pickle para optimizar la carga, y crear embeddings a partir de archivos de texto si no existe la versión serializada. También incluye métodos de acceso y conversión de índices a palabras y de palabras a índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ZgqtV8GpkSc8"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "import pickle\n",
    "\n",
    "class WordsEmbeddings(object):\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    def __init__(self):\n",
    "        embedding_file = Path(self.PKL_PATH)\n",
    "        if not embedding_file.exists():\n",
    "            text_embedding_file = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
    "            assert text_embedding_file.exists(), 'Embedding file missing'\n",
    "            word_vectors = self._create_pickle_embeddings()\n",
    "        else:\n",
    "            word_vectors = self._load_pickle_embeddings()\n",
    "\n",
    "        self.word_vectors = word_vectors\n",
    "\n",
    "        indices = np.arange(self.word_vectors.shape[0])\n",
    "        self.word_to_index = dict(zip(self.word_vectors['word'], indices))\n",
    "        self.index_to_word = dict(zip(indices, self.word_vectors['word']))\n",
    "\n",
    "    def get_words_embeddings(self, word_list):\n",
    "        indices = self._convert_words_to_indices(word_list)\n",
    "        return self.word_vectors[indices]['embedding']\n",
    "\n",
    "    def _convert_words_to_indices(self, word_list):\n",
    "        return np.array([self.word_to_index.get(word, -1) for word in word_list])\n",
    "\n",
    "    def _convert_indices_to_words(self, indices):\n",
    "        return np.array([self.index_to_word.get(idx, '-1') for idx in indices])\n",
    "\n",
    "    def _load_pickle_embeddings(self):\n",
    "        self.logger.debug(f'Loading embeddings from {self.PKL_PATH}')\n",
    "        chunk_size = 2**28 - 1\n",
    "        data_bytes = bytearray(0)\n",
    "        file_size = os.path.getsize(self.PKL_PATH)\n",
    "        with open(self.PKL_PATH, 'rb') as file:\n",
    "            for _ in range(0, file_size, chunk_size):\n",
    "                data_bytes += file.read(chunk_size)\n",
    "        embeddings = pickle.loads(data_bytes)\n",
    "        self.logger.debug('Embeddings loaded successfully')\n",
    "        return embeddings\n",
    "\n",
    "    def _create_pickle_embeddings(self):\n",
    "        self.logger.debug(f'Converting embeddings from {self.WORD_TO_VEC_MODEL_TXT_PATH}')\n",
    "        dtype_spec = [\n",
    "            ('word', np.dtype(f'U{self.WORD_MAX_SIZE}')),\n",
    "            ('embedding', np.float32, (self.N_FEATURES,))\n",
    "        ]\n",
    "        structure = np.dtype(dtype_spec)\n",
    "\n",
    "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as text_file:\n",
    "            embedding_generator = (\n",
    "                (line.split()[0], line.split()[1:]) for line in text_file\n",
    "                if len(line.split()[1:]) == self.N_FEATURES\n",
    "            )\n",
    "            embeddings_array = np.fromiter(embedding_generator, structure)\n",
    "\n",
    "        empty_embedding = np.array(\n",
    "            [('empty_token', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
    "            dtype=structure\n",
    "        )\n",
    "        embeddings_array = np.concatenate([embeddings_array, empty_embedding])\n",
    "\n",
    "        max_bytes = 2**28 - 1\n",
    "        serialized_data = pickle.dumps(embeddings_array, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(self.PKL_PATH, 'wb') as output_file:\n",
    "            for pos in range(0, len(serialized_data), max_bytes):\n",
    "                output_file.write(serialized_data[pos:pos+max_bytes])\n",
    "\n",
    "        self.logger.debug('Embeddings conversion completed')\n",
    "        return embeddings_array\n",
    "\n",
    "\n",
    "class GloveEmbeddings(WordsEmbeddings):\n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
    "    PKL_PATH = 'gloveembedding.pkl'\n",
    "    N_FEATURES = 50\n",
    "    WORD_MAX_SIZE = 60\n",
    "\n",
    "class FasttextEmbeddings(WordsEmbeddings):\n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
    "    PKL_PATH = 'fasttext.pkl'\n",
    "    N_FEATURES = 300\n",
    "    WORD_MAX_SIZE = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Mosj2-x-kXBK"
   },
   "outputs": [],
   "source": [
    "# Por una cuestion de RAM se utilizará los embeddings de Glove de dimension 50\n",
    "model_embeddings = GloveEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9FS8ca1ke_B",
    "outputId": "8238a522-1c16-4187-e3d3-9a7b371d392c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing embedding matrix...\n",
      "number of null word embeddings: 98\n"
     ]
    }
   ],
   "source": [
    "# Crear la Embedding matrix de las secuencias\n",
    "# en ingles\n",
    "\n",
    "print('preparing embedding matrix...')\n",
    "embed_dim = model_embeddings.N_FEATURES\n",
    "words_not_found = []\n",
    "\n",
    "# word_index provieen del tokenizer\n",
    "\n",
    "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs)) # vocab_size\n",
    "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n",
    "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        words_not_found.append(word)\n",
    "\n",
    "print('number of null word embeddings:', np.sum(np.sum(embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vKbhjtIwPgM"
   },
   "source": [
    "### 4 - Entrenar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVwOLv-yic7w"
   },
   "source": [
    "Esta celda define la arquitectura de la red secuencial para traducción basada en PyTorch. Se incluyen tres clases principales: EncoderNetwork, que codifica la secuencia de entrada en un estado oculto utilizando embeddings preentrenados y LSTM; DecoderNetwork, que decodifica el estado oculto para generar predicciones de salida palabra por palabra; y SequenceModel, que integra el encoder y el decoder en un modelo completo. También se inicializan el modelo, el optimizador y la función de pérdida, y se imprime un resumen de la arquitectura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fm3HCLMPSG-",
    "outputId": "14664b1f-8650-42ae-b382-344dbd846324"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SequenceModel                            [1, 50, 13918]            --\n",
       "├─EncoderNetwork: 1-1                    [1, 1, 128]               --\n",
       "│    └─Embedding: 2-1                    [1, 50, 50]               (404,250)\n",
       "│    └─LSTM: 2-2                         [1, 50, 128]              92,160\n",
       "├─DecoderNetwork: 1-2                    --                        --\n",
       "│    └─Embedding: 2-3                    [1, 50, 50]               695,900\n",
       "│    └─LSTM: 2-4                         [1, 50, 128]              92,160\n",
       "│    └─Linear: 2-5                       [1, 50, 13918]            1,795,422\n",
       "==========================================================================================\n",
       "Total params: 3,079,892\n",
       "Trainable params: 2,675,642\n",
       "Non-trainable params: 404,250\n",
       "Total mult-adds (Units.MEGABYTES): 12.11\n",
       "==========================================================================================\n",
       "Input size (MB): 11.90\n",
       "Forward/backward pass size (MB): 5.71\n",
       "Params size (MB): 12.32\n",
       "Estimated Total Size (MB): 29.93\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderNetwork(nn.Module):\n",
    "    def __init__(self, vocab_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = 128\n",
    "        self.n_layers = 1\n",
    "        self.embed_dim = embed_dim\n",
    "        self.embed_layer = nn.Embedding(num_embeddings=vocab_dim, embedding_dim=self.embed_dim, padding_idx=0)\n",
    "        self.embed_layer.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "        self.embed_layer.weight.requires_grad = False\n",
    "        self.lstm_cell = nn.LSTM(input_size=self.embed_dim, hidden_size=self.hidden_dim, batch_first=True,\n",
    "                                num_layers=self.n_layers)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embedded = self.embed_layer(input_seq)\n",
    "        lstm_out, hidden_state = self.lstm_cell(embedded)\n",
    "        return hidden_state\n",
    "\n",
    "class DecoderNetwork(nn.Module):\n",
    "    def __init__(self, vocab_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = 128\n",
    "        self.n_layers = 1\n",
    "        self.embed_dim = embed_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.embed_layer = nn.Embedding(num_embeddings=vocab_dim, embedding_dim=self.embed_dim, padding_idx=0)\n",
    "        self.lstm_cell = nn.LSTM(input_size=self.embed_dim, hidden_size=self.hidden_dim, batch_first=True,\n",
    "                                num_layers=self.n_layers)\n",
    "        self.output_layer = nn.Linear(in_features=self.hidden_dim, out_features=self.output_dim)\n",
    "\n",
    "    def forward(self, input_seq, prev_hidden):\n",
    "        embedded = self.embed_layer(input_seq)\n",
    "        lstm_out, current_hidden = self.lstm_cell(embedded, prev_hidden)\n",
    "        predictions = self.output_layer(lstm_out[:, -1, :])\n",
    "        return predictions, current_hidden\n",
    "\n",
    "class SequenceModel(nn.Module):\n",
    "    def __init__(self, encoder_net, decoder_net):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder_net = encoder_net\n",
    "        self.decoder_net = decoder_net\n",
    "\n",
    "        assert encoder_net.hidden_dim == decoder_net.hidden_dim, \\\n",
    "            \"Encoder and decoder hidden dimensions must match\"\n",
    "        assert encoder_net.n_layers == decoder_net.n_layers, \\\n",
    "            \"Encoder and decoder layer counts must match\"\n",
    "\n",
    "    def forward(self, enc_input, dec_input):\n",
    "        hidden_state = self.encoder_net(enc_input)\n",
    "        decoder_output, _ = self.decoder_net.lstm_cell(self.decoder_net.embed_layer(dec_input), hidden_state)\n",
    "        final_output = self.decoder_net.output_layer(decoder_output)\n",
    "        return final_output\n",
    "\n",
    "encoder_net = EncoderNetwork(vocab_dim=nb_words)\n",
    "if cuda: encoder_net.cuda()\n",
    "\n",
    "decoder_net = DecoderNetwork(vocab_dim=num_words_output, output_dim=num_words_output)\n",
    "if cuda: decoder_net.cuda()\n",
    "\n",
    "model = SequenceModel(encoder_net, decoder_net)\n",
    "if cuda: model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "if cuda:\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "enc_sample, dec_input_sample, dec_output_sample = data_set[0:1]\n",
    "summary(model, input_data=(enc_sample.to(device), dec_input_sample.to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H85wlw3BZ5Wl",
    "outputId": "eb3d50df-14ed-42ba-90d9-a811185b62a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 - Train loss 0.810 - Train accuracy 0.886 - Valid Loss 0.585 - Valid accuracy 0.906\n",
      "Epoch: 2/10 - Train loss 0.614 - Train accuracy 0.897 - Valid Loss 0.538 - Valid accuracy 0.915\n",
      "Epoch: 3/10 - Train loss 0.531 - Train accuracy 0.902 - Valid Loss 0.527 - Valid accuracy 0.914\n",
      "Epoch: 4/10 - Train loss 0.471 - Train accuracy 0.907 - Valid Loss 0.534 - Valid accuracy 0.915\n",
      "Epoch: 5/10 - Train loss 0.424 - Train accuracy 0.912 - Valid Loss 0.551 - Valid accuracy 0.915\n",
      "Epoch: 6/10 - Train loss 0.387 - Train accuracy 0.917 - Valid Loss 0.567 - Valid accuracy 0.915\n",
      "Epoch: 7/10 - Train loss 0.357 - Train accuracy 0.922 - Valid Loss 0.579 - Valid accuracy 0.913\n",
      "Epoch: 8/10 - Train loss 0.332 - Train accuracy 0.926 - Valid Loss 0.579 - Valid accuracy 0.915\n",
      "Epoch: 9/10 - Train loss 0.313 - Train accuracy 0.929 - Valid Loss 0.608 - Valid accuracy 0.918\n",
      "Epoch: 10/10 - Train loss 0.298 - Train accuracy 0.932 - Valid Loss 0.606 - Valid accuracy 0.918\n"
     ]
    }
   ],
   "source": [
    "hist = train(model,train_dl,val_dl,optimizer,criterion,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "pZzm3tx059Zv"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "epoch_count = range(1, len(hist['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=hist['accuracy'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=hist['val_accuracy'], label='valid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8n75Sopih23"
   },
   "source": [
    "El modelo ya alcanzó su punto óptimo muy temprano y seguir entrenando no mejora el rendimiento en datos nuevos. El valor de precisión se considera aceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zbwn0ekDy_s2"
   },
   "source": [
    "### 5 - Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "71XeCtfYmOFx"
   },
   "outputs": [],
   "source": [
    "# Armar lo conversores de indice a palabra:\n",
    "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "MlUyp9M6ua2V"
   },
   "outputs": [],
   "source": [
    "def translate_sentence(input_seq):\n",
    "    # Se transforma la sequencia de entrada a los stados \"h\" y \"c\" de la LSTM\n",
    "    # para enviar la primera vez al decoder\"\n",
    "    prev_state = model.encoder_net(encoder_sequence_test_tensor.to(device))\n",
    "\n",
    "    # Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "    target_seq_tensor = torch.from_numpy(target_seq.astype(np.int32))\n",
    "\n",
    "    # Se obtiene el indice que finaliza la inferencia\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "\n",
    "    output_sentence = []\n",
    "    for _ in range(max_out_len):\n",
    "        # Predicción del próximo elemento\n",
    "        output, new_prev_state = model.decoder_net(target_seq_tensor.to(device), prev_state)\n",
    "        top1 = output.argmax(1).view(-1, 1)\n",
    "        idx = int(top1.cpu())\n",
    "\n",
    "        # Si es \"end of sentece <eos>\" se acaba\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        # Transformar ídx a palabra\n",
    "        word = ''\n",
    "        if idx > 0:\n",
    "            word = idx2word_target[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        # Actualizar los estados dado la ultimo prediccion\n",
    "        prev_state = new_prev_state\n",
    "\n",
    "        # Actualizar secuencia de entrada con la salida (re-alimentacion)\n",
    "        target_seq_tensor = top1\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ZhGVjLKcunxW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input: Tom is naked.\n",
      "Response: tom es un embustero\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "encoder_sequence_test_tensor = torch.from_numpy(input_seq.astype(np.int32))\n",
    "translation = translate_sentence(encoder_sequence_test_tensor)\n",
    "print('-')\n",
    "print('Input:', input_sentences[i])\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "9QG02lr1bWJa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input: I can't hear you.\n",
      "Response: no puedo culparos\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "encoder_sequence_test_tensor = torch.from_numpy(input_seq.astype(np.int32))\n",
    "translation = translate_sentence(encoder_sequence_test_tensor)\n",
    "print('-')\n",
    "print('Input:', input_sentences[i])\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "VM9yKVGTbXjy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input: I've got nothing to say to him.\n",
      "Response: no puedo evitar pensar que tom\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "encoder_sequence_test_tensor = torch.from_numpy(input_seq.astype(np.int32))\n",
    "translation = translate_sentence(encoder_sequence_test_tensor)\n",
    "print('-')\n",
    "print('Input:', input_sentences[i])\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Xv9jmE6_bXmi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input: She seemed to be suffering a heart attack.\n",
      "Response: ella no pudo entender ni una sola palabra\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "encoder_sequence_test_tensor = torch.from_numpy(input_seq.astype(np.int32))\n",
    "translation = translate_sentence(encoder_sequence_test_tensor)\n",
    "print('-')\n",
    "print('Input:', input_sentences[i])\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "nmmO_WyObV0Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input: Don't pretend what you don't feel.\n",
      "Response: no dejes que te sientas tengas\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "encoder_sequence_test_tensor = torch.from_numpy(input_seq.astype(np.int32))\n",
    "translation = translate_sentence(encoder_sequence_test_tensor)\n",
    "print('-')\n",
    "print('Input:', input_sentences[i])\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vta8soxYikqG"
   },
   "source": [
    "Solucionados los problemas de compatibilidades y con la idea de poder usar la totalidad del dataset para el entrenamiento, se reemplazo la implementación del one-hot que consumia demasiada ram, se aumentó el tamaño del dataset.\n",
    "El modelo implmentado en eta notebook es el mas grande que llegué a correr hasta ahora. Modelos mas chicos. menos neuronas, arrojaron resultados peores. El modelo corre consiedrablemente mas rápido en GPU (colab) pero experimenté muchos problemas de conexión con el servidor \n",
    "Si bien el modelo respeta el orden gramatical general del españo y genera frases cohorentes, el embedding y la arquitectura seq2seq funciona, las traducciones son débiles o incompletas y se pierde la semantica de las oraciones. Esto es probable que se pueda solucionar aumentando aún mas el tamaño del dataset o aumentando las capas LSTM. La arquitectura implementada no requiere de demasiadas epochs para la convergencia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
