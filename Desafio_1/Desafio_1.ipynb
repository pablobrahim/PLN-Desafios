{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## Desafio 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJgf6GQIIEH1"
   },
   "source": [
    "**1**. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
    "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido\n",
    "la similaridad según el contenido del texto y la etiqueta de clasificación.\n",
    "\n",
    "**2**. Construir un modelo de clasificación por prototipos (tipo zero-shot). Clasificar los documentos de un conjunto de test comparando cada uno con todos los de entrenamiento y asignar la clase al label del documento del conjunto de entrenamiento con mayor similaridad.\n",
    "\n",
    "**3**. Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
    "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros\n",
    "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
    "y ComplementNB.\n",
    "\n",
    "**4**. Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
    "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
    "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares. La elección de palabras no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos de entrenamiento luego de limpieza: 10892\n",
      "Documentos de test luego de limpieza: 7226\n",
      "Cantidad de documentos de entrenamiento: 10892\n",
      "Cantidad de documentos de test: 7226\n",
      "Cantidad de clases: 20\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# Carga del dataset\n",
    "# --------------------------------------\n",
    "\n",
    "train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "test  = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "X_train = train.data\n",
    "y_train = train.target\n",
    "X_test  = test.data\n",
    "y_test  = test.target\n",
    "target_names = train.target_names\n",
    "\n",
    "# --- 🔹 Limpiar documentos vacíos ---\n",
    "def limpiar_docs(textos, etiquetas):\n",
    "    X_limpio, y_limpio = [], []\n",
    "    for x, y in zip(textos, etiquetas):\n",
    "        x_clean = (x or \"\").strip()\n",
    "        if len(x_clean) > 30:\n",
    "            X_limpio.append(x_clean)\n",
    "            y_limpio.append(y)\n",
    "    return X_limpio, y_limpio\n",
    "\n",
    "X_train, y_train = limpiar_docs(X_train, y_train)\n",
    "X_test, y_test = limpiar_docs(X_test, y_test)\n",
    "\n",
    "print(f\"Documentos de entrenamiento luego de limpieza: {len(X_train)}\")\n",
    "print(f\"Documentos de test luego de limpieza: {len(X_test)}\")\n",
    "\n",
    "print(f\"Cantidad de documentos de entrenamiento: {len(X_train)}\")\n",
    "print(f\"Cantidad de documentos de test: {len(X_test)}\")\n",
    "print(f\"Cantidad de clases: {len(target_names)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Documento índice 12623 (test) — etiqueta: misc.forsale\n",
      "Extracto: Sharp brand \"Pocket Computer\" model PC-1246     Dimensions;  3.5 x 5 x 0.5 inches.          Has 15-digit LCD display         53 rubber keys (w/alphabet)         built-in BASIC prog.language         an \n",
      "\n",
      "  • idx  4026 | train | label=rec.autos                 | similitud=0.1690\n",
      "  • idx   370 | train | label=sci.electronics           | similitud=0.1644\n",
      "  • idx 12058 | test  | label=comp.graphics             | similitud=0.1570\n",
      "  • idx 11436 | test  | label=comp.sys.ibm.pc.hardware  | similitud=0.1494\n",
      "  • idx  8680 | train | label=misc.forsale              | similitud=0.1458\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Documento índice 13781 (test) — etiqueta: misc.forsale\n",
      "Extracto: Hallo all...my girlfriend and I will be travelling across the US this summer, so we won't be using our tickets to return to Hawaii.  Please buy them.  The tickets are one-way, leaving Peoria, IL on Ma \n",
      "\n",
      "  • idx   108 | train | label=misc.forsale              | similitud=0.2557\n",
      "  • idx  2277 | train | label=rec.sport.hockey          | similitud=0.2251\n",
      "  • idx 16599 | test  | label=rec.sport.baseball        | similitud=0.2090\n",
      "  • idx 17206 | test  | label=misc.forsale              | similitud=0.1992\n",
      "  • idx 17875 | test  | label=misc.forsale              | similitud=0.1992\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Documento índice 1326 (train) — etiqueta: talk.politics.mideast\n",
      "Extracto: Mr. Emmanuel Huna,  Give logic a break will you.  Gosh, what kind of intelligence do you have, if any?   Tesiel says :  Be a man not an arab for once. I say       :  Fuck of Tsiel (for saying the abov \n",
      "\n",
      "  • idx  4678 | train | label=talk.politics.mideast     | similitud=0.2026\n",
      "  • idx  1164 | train | label=rec.sport.hockey          | similitud=0.1795\n",
      "  • idx  7513 | train | label=rec.sport.hockey          | similitud=0.1639\n",
      "  • idx  9224 | train | label=talk.politics.misc        | similitud=0.1458\n",
      "  • idx 11696 | test  | label=talk.politics.mideast     | similitud=0.1260\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Documento índice 8484 (train) — etiqueta: rec.autos\n",
      "Extracto: The Olds Supreme Convertible got high marks in C/D's recent test, if you can get by the stupid body moldings and stuff.  The Saab 900 ragtop may be out of your range, but its a good choice.  Is there  \n",
      "\n",
      "  • idx 18089 | test  | label=rec.autos                 | similitud=0.4621\n",
      "  • idx  4828 | train | label=rec.autos                 | similitud=0.4275\n",
      "  • idx 14020 | test  | label=rec.autos                 | similitud=0.4017\n",
      "  • idx  5608 | train | label=rec.autos                 | similitud=0.2872\n",
      "  • idx  1011 | train | label=rec.autos                 | similitud=0.2846\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Documento índice 16753 (test) — etiqueta: misc.forsale\n",
      "Extracto: I have the following Marx Brothers tapes forsale. I would like to sell them as a batch if possible. All (except *) are new, carfully stored copies I bought. I now own the laserdisks.  MGM/UA: A Day at \n",
      "\n",
      "  • idx 17246 | test  | label=misc.forsale              | similitud=0.2985\n",
      "  • idx 16497 | test  | label=misc.forsale              | similitud=0.2776\n",
      "  • idx 15745 | test  | label=misc.forsale              | similitud=0.2420\n",
      "  • idx 16336 | test  | label=misc.forsale              | similitud=0.2234\n",
      "  • idx  8171 | train | label=talk.religion.misc        | similitud=0.1519\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# 1. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
    "#    Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido la similaridad según el \n",
    "#    contenido del texto y la etiqueta de clasificación\n",
    "# --------------------------------------\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=2)\n",
    "X_all = vectorizer.fit_transform(X_train + X_test)\n",
    "all_data = X_train + X_test\n",
    "n_train = len(X_train)\n",
    "\n",
    "# Seleccionamos 5 documentos al azar\n",
    "random.seed(0)\n",
    "indices = random.sample(range(X_all.shape[0]), 5)\n",
    "\n",
    "for idx in indices:\n",
    "    sim = cosine_similarity(X_all[idx], X_all).ravel()\n",
    "    sim[idx] = 0  # Evitar el mismo documento\n",
    "    top5 = sim.argsort()[-5:][::-1]\n",
    "\n",
    "    # Determinar conjunto y etiqueta del documento original\n",
    "    if idx < n_train:\n",
    "        label = target_names[y_train[idx]]\n",
    "        subset = \"train\"\n",
    "    else:\n",
    "        label = target_names[y_test[idx - n_train]]\n",
    "        subset = \"test\"\n",
    "\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(f\"Documento índice {idx} ({subset}) — etiqueta: {label}\")\n",
    "    print(\"Extracto:\", all_data[idx][:200].replace(\"\\n\", \" \"), \"\\n\")\n",
    "\n",
    "    for j in top5:\n",
    "        if j < n_train:\n",
    "            lab = target_names[y_train[j]]\n",
    "            subset_j = \"train\"\n",
    "        else:\n",
    "            lab = target_names[y_test[j - n_train]]\n",
    "            subset_j = \"test\"\n",
    "        print(f\"  • idx {j:5d} | {subset_j:5s} | label={lab:25s} | similitud={sim[j]:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis de similaridad utilizando la representación TF-IDF muestra resultados coherentes en la mayoría de los casos.\n",
    "Por ejemplo, los documentos con etiqueta misc.forsale presentan como más similares otros textos también pertenecientes a esa categoría, lo que tiene sentido porque contienen términos asociados a ventas (“for sale”, “buy”, “tickets”, “batch”, “copies”, “price”, etc.).\n",
    "También se observa que, cuando los documentos tratan de temas más técnicos o específicos —como rec.autos o talk.politics.mideast—, las similitudes altas suelen darse con documentos de la misma clase o de clases temáticamente cercanas.\n",
    "Igualmente, aparecen algunos casos en los que documentos de distintas categorías muestran similitudes no triviales. Esto se debe a que la representación TF-IDF no captura el contexto semántico profundo, sino la coocurrencia de términos. Entonces, palabras mas genéricas pueden estar presentes en múltiples categorías técnicas, afectando la medida de similitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CLASIFICADOR POR PROTOTIPOS\n",
      "Accuracy: 0.5569\n",
      "F1 macro: 0.5492\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# 2. Construir un modelo de clasificación por prototipos (tipo zero-shot). Clasificar los documentos de un conjunto\n",
    "#    de test comparando cada uno con todos los de entrenamiento y asignar la clase al label del documento del conjunto\n",
    "#    de entrenamiento con mayor similaridad. \n",
    "# --------------------------------------\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=2)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec  = vectorizer.transform(X_test)\n",
    "\n",
    "y_pred_proto = []\n",
    "for i in range(X_test_vec.shape[0]):\n",
    "    sims = cosine_similarity(X_test_vec[i], X_train_vec).ravel()\n",
    "    best = np.argmax(sims)\n",
    "    y_pred_proto.append(y_train[best])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASIFICADOR POR PROTOTIPOS\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_proto):.4f}\")\n",
    "print(f\"F1 macro: {f1_score(y_test, y_pred_proto, average='macro'):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo tipo “zero-shot” basado en comparación de similaridad con los documentos de entrenamiento alcanza un accuracy de 0.56 y un F1 macro de 0.55, lo cual es razonable considerando su sencillez y la naturaleza no supervisada del enfoque.\n",
    "En este tipo de modelo, cada documento de test se asigna a la clase del documento más similar en entrenamiento. Esto implica que:\n",
    "Es muy sensible al \"ruido\" en los textos.\n",
    "No aprovecha la distribución global de las clases, sino que se apoya en un único ejemplo.\n",
    "Depende fuertemente de la calidad de la representación vectorial.\n",
    "El rendimiento obtenido sugiere que la representación TF-IDF logra capturar cierta estructura temática, pero no lo suficiente como para generalizar bien a nuevos textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODELO: CountVectorizer + MultinomialNB\n",
      "Accuracy: 0.6742\n",
      "F1 macro: 0.6408\n",
      "\n",
      "Reporte de clasificación (resumen):\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.58      0.48      0.53       306\n",
      "           comp.graphics       0.55      0.73      0.63       380\n",
      " comp.os.ms-windows.misc       0.33      0.00      0.01       378\n",
      "comp.sys.ibm.pc.hardware       0.51      0.75      0.60       382\n",
      "   comp.sys.mac.hardware       0.68      0.66      0.67       369\n",
      "          comp.windows.x       0.63      0.77      0.70       382\n",
      "            misc.forsale       0.84      0.74      0.79       377\n",
      "               rec.autos       0.78      0.77      0.77       369\n",
      "         rec.motorcycles       0.85      0.73      0.79       378\n",
      "      rec.sport.baseball       0.92      0.82      0.87       374\n",
      "        rec.sport.hockey       0.94      0.87      0.90       387\n",
      "               sci.crypt       0.65      0.80      0.72       371\n",
      "         sci.electronics       0.67      0.53      0.59       379\n",
      "                 sci.med       0.83      0.83      0.83       379\n",
      "               sci.space       0.78      0.77      0.78       376\n",
      "  soc.religion.christian       0.52      0.91      0.66       384\n",
      "      talk.politics.guns       0.57      0.69      0.62       347\n",
      "   talk.politics.mideast       0.74      0.77      0.76       366\n",
      "      talk.politics.misc       0.43      0.45      0.44       301\n",
      "      talk.religion.misc       0.37      0.10      0.16       241\n",
      "\n",
      "                accuracy                           0.67      7226\n",
      "               macro avg       0.66      0.66      0.64      7226\n",
      "            weighted avg       0.67      0.67      0.65      7226\n",
      "\n",
      "\n",
      "======================================================================\n",
      "MODELO: TFIDF + MultinomialNB\n",
      "Accuracy: 0.7050\n",
      "F1 macro: 0.6740\n",
      "\n",
      "Reporte de clasificación (resumen):\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.74      0.20      0.31       306\n",
      "           comp.graphics       0.66      0.71      0.69       380\n",
      " comp.os.ms-windows.misc       0.68      0.61      0.64       378\n",
      "comp.sys.ibm.pc.hardware       0.60      0.76      0.67       382\n",
      "   comp.sys.mac.hardware       0.79      0.69      0.74       369\n",
      "          comp.windows.x       0.79      0.78      0.78       382\n",
      "            misc.forsale       0.78      0.81      0.80       377\n",
      "               rec.autos       0.84      0.77      0.80       369\n",
      "         rec.motorcycles       0.86      0.78      0.82       378\n",
      "      rec.sport.baseball       0.94      0.85      0.89       374\n",
      "        rec.sport.hockey       0.89      0.93      0.91       387\n",
      "               sci.crypt       0.63      0.84      0.72       371\n",
      "         sci.electronics       0.70      0.55      0.62       379\n",
      "                 sci.med       0.89      0.79      0.84       379\n",
      "               sci.space       0.77      0.78      0.77       376\n",
      "  soc.religion.christian       0.38      0.96      0.54       384\n",
      "      talk.politics.guns       0.57      0.75      0.65       347\n",
      "   talk.politics.mideast       0.83      0.80      0.81       366\n",
      "      talk.politics.misc       0.87      0.32      0.46       301\n",
      "      talk.religion.misc       0.67      0.01      0.02       241\n",
      "\n",
      "                accuracy                           0.70      7226\n",
      "               macro avg       0.74      0.68      0.67      7226\n",
      "            weighted avg       0.74      0.70      0.69      7226\n",
      "\n",
      "\n",
      "======================================================================\n",
      "MODELO: TFIDF + ComplementNB\n",
      "Accuracy: 0.7382\n",
      "F1 macro: 0.7147\n",
      "\n",
      "Reporte de clasificación (resumen):\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.60      0.42      0.49       306\n",
      "           comp.graphics       0.71      0.73      0.72       380\n",
      " comp.os.ms-windows.misc       0.70      0.65      0.67       378\n",
      "comp.sys.ibm.pc.hardware       0.64      0.71      0.68       382\n",
      "   comp.sys.mac.hardware       0.77      0.75      0.76       369\n",
      "          comp.windows.x       0.81      0.79      0.80       382\n",
      "            misc.forsale       0.77      0.76      0.76       377\n",
      "               rec.autos       0.82      0.79      0.80       369\n",
      "         rec.motorcycles       0.83      0.80      0.82       378\n",
      "      rec.sport.baseball       0.93      0.88      0.90       374\n",
      "        rec.sport.hockey       0.85      0.95      0.90       387\n",
      "               sci.crypt       0.77      0.85      0.81       371\n",
      "         sci.electronics       0.71      0.57      0.63       379\n",
      "                 sci.med       0.83      0.84      0.83       379\n",
      "               sci.space       0.79      0.84      0.81       376\n",
      "  soc.religion.christian       0.55      0.92      0.69       384\n",
      "      talk.politics.guns       0.59      0.76      0.66       347\n",
      "   talk.politics.mideast       0.81      0.86      0.83       366\n",
      "      talk.politics.misc       0.65      0.44      0.52       301\n",
      "      talk.religion.misc       0.48      0.12      0.19       241\n",
      "\n",
      "                accuracy                           0.74      7226\n",
      "               macro avg       0.73      0.72      0.71      7226\n",
      "            weighted avg       0.74      0.74      0.73      7226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# 3. Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación \n",
    "#    (f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros de instanciación \n",
    "#    del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial y ComplementNB.\n",
    "# --------------------------------------\n",
    "\n",
    "configs = [\n",
    "    (\"CountVectorizer + MultinomialNB\", CountVectorizer(stop_words='english', min_df=2), MultinomialNB()),\n",
    "    (\"TFIDF + MultinomialNB\", TfidfVectorizer(stop_words='english', min_df=2), MultinomialNB()),\n",
    "    (\"TFIDF + ComplementNB\", TfidfVectorizer(stop_words='english', min_df=2), ComplementNB())\n",
    "]\n",
    "\n",
    "for name, vect, model in configs:\n",
    "    Xtr = vect.fit_transform(X_train)\n",
    "    Xte = vect.transform(X_test)\n",
    "\n",
    "    model.fit(Xtr, y_train)\n",
    "    y_pred = model.predict(Xte)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1m = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"MODELO: {name}\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 macro: {f1m:.4f}\")\n",
    "    print(\"\\nReporte de clasificación (resumen):\")\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados de los tres modelos probados muestran una mejora significativa:\n",
    "\n",
    "Modelo\tAccuracy\tF1-macro\n",
    "CountVectorizer + MultinomialNB\t0.67\t0.64\n",
    "TF-IDF + MultinomialNB\t0.71\t0.67\n",
    "TF-IDF + ComplementNB\t0.74\t0.71\n",
    "\n",
    "El mejor desempeño se obtuvo con TF-IDF + ComplementNB, lo que concuerda con la teoría: el modelo ComplementNB está diseñado para manejar mejor clases desbalanceadas y situaciones donde las características mas discriminativas aparecen con baja frecuencia.\n",
    "\n",
    "El uso de TF-IDF también mejora el rendimiento respecto a los conteos crudos, al ponderar las palabras más informativas y reducir el peso de términos comunes.\n",
    "Las categorías con temas más técnicos y vocabularios más especializados (por ejemplo, rec.autos, rec.sport.hockey, sci.med, sci.space) son las mejor clasificadas, mientras que las más ambiguas o con contenido variado (talk.religion.misc, alt.atheism, talk.politics.misc) presentan menor desempeño.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Palabra: 'space' — más similares:\n",
      "  • nasa             (similitud = 0.3179)\n",
      "  • shuttle          (similitud = 0.2784)\n",
      "  • exploration      (similitud = 0.2329)\n",
      "  • aeronautics      (similitud = 0.2221)\n",
      "  • sci              (similitud = 0.2167)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Palabra: 'computer' — más similares:\n",
      "  • shopper          (similitud = 0.1349)\n",
      "  • verlag           (similitud = 0.1248)\n",
      "  • delicate         (similitud = 0.1197)\n",
      "  • drive            (similitud = 0.1106)\n",
      "  • hackers          (similitud = 0.1082)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Palabra: 'car' — más similares:\n",
      "  • cars             (similitud = 0.1923)\n",
      "  • dealer           (similitud = 0.1773)\n",
      "  • civic            (similitud = 0.1635)\n",
      "  • loan             (similitud = 0.1561)\n",
      "  • owner            (similitud = 0.1484)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Palabra: 'engine' — más similares:\n",
      "  • household        (similitud = 0.1732)\n",
      "  • exhaust          (similitud = 0.1714)\n",
      "  • rebuilt          (similitud = 0.1706)\n",
      "  • oil              (similitud = 0.1594)\n",
      "  • diesel           (similitud = 0.1574)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Palabra: 'religion' — más similares:\n",
      "  • religious        (similitud = 0.2476)\n",
      "  • religions        (similitud = 0.2237)\n",
      "  • crusades         (similitud = 0.1937)\n",
      "  • christianity     (similitud = 0.1881)\n",
      "  • categorized      (similitud = 0.1848)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# 4. Transponer la matriz documento-término. De esa manera se obtiene una matriz término-documento\n",
    "#    que puede ser interpretada como una colección de vectorización de palabras. Estudiar ahora \n",
    "#    similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares. La elección de palabras\n",
    "#    no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\".\n",
    "# --------------------------------------\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', min_df=5)\n",
    "X_tfidf = tfidf.fit_transform(X_train)\n",
    "terms = np.array(tfidf.get_feature_names_out())\n",
    "# Transponer: filas = palabras, columnas = documentos\n",
    "term_doc = X_tfidf.T\n",
    "sim_matrix = cosine_similarity(term_doc)\n",
    "\n",
    "selected_words = [\"space\", \"computer\", \"car\", \"engine\", \"religion\"]\n",
    "\n",
    "for w in selected_words:\n",
    "    if w not in tfidf.vocabulary_:\n",
    "        print(f\"\\nPalabra '{w}' no encontrada en el vocabulario.\")\n",
    "        continue\n",
    "\n",
    "    idx = tfidf.vocabulary_[w]\n",
    "    sims = sim_matrix[idx]\n",
    "    sims[idx] = 0\n",
    "    top5 = sims.argsort()[-5:][::-1]\n",
    "\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(f\"Palabra: '{w}' — más similares:\")\n",
    "    for j in top5:\n",
    "        print(f\"  • {terms[j]:15s}  (similitud = {sims[j]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las similitudes obtenidas son, en general, coherentes y temáticamente precisas, especialmente en dominios bien representados en el corpus (como “space”, “car” o “religion”).\n",
    "En cambio, ciertos términos más genéricos o dispersos (“computer”) presentan asociaciones menos claras, lo que podría mejorarse, por ejemplo, mediante ponderación TF-IDF, reducción de dimensionalidad, o un corpus más especializado.\n",
    "El análisis confirma que la transposición de la matriz y la representación término-documento permite explorar con éxito relaciones semánticas entre palabras a partir de coocurrencias contextuales."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
